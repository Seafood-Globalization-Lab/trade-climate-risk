---
title: "Seafood Analysis"
author: "Connor Quiroz"
date: "2024-11-15"
output: html_document
---

# Setup / Load in Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# General data cleaning + visualization + analysis packages
library(tidyverse)
library(ggformula)
library(countrycode)
library(data.table)
library(arrow)
library(cowplot)
library(RColorBrewer)

# Map creation
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)

# Load in packages needed for ARTIS
library(devtools)
library(tidytext)
# devtools::install_github("davidsjoberg/ggsankey")
library(ggsankey)
# devtools::install_github("Seafood-Globalization-Lab/exploreARTIS@v1.0.0", dependencies = TRUE)
library(exploreARTIS)

# For Packages for fishbase
# remotes::install_github("cboettig/duckdbfs", force = TRUE)
# remotes::install_github("ropensci/rfishbase")
library(duckdbfs)
library(rfishbase)
```

```{r initialize functions}
# Ocean polygon
ocean <- st_polygon(list(cbind(c(seq(-180, 179, len = 100), rep(180, 100), 
                        seq(179, -180, len = 100), rep(-180, 100)),
                      c(rep(-90, 100), seq(-89, 89, len = 100),
                        rep(90, 100), seq(89, -90, len = 100))))) |>
  st_sfc(crs = "WGS84") |>
  st_as_sf()

create_map <- function(data, fill = "prop_missing") {
  world_map <- ne_countries(scale = "medium", returnclass = "sf")

world_map <- world_map %>%
  left_join(data, by = c("iso_a3" = "eez_iso3c"))
  
  world_map %>%
ggplot() +
  geom_sf(data = ocean, fill = "#8080ff80") +
  geom_sf(aes(fill = !!sym(fill)), color = "black") + 
  scale_fill_viridis_c(option = "plasma") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  coord_sf(crs = "+proj=robin")
}
```


# Data Cleaning

```{r new preprocess future climate data}
file_names <- list.files(path = "../data/exposure/mcp_per_change/mcp_per_change/", pattern = "\\.csv", full.names = TRUE)

# Obtain species lookup key (will be used in loop join)
species_names <- fread("../data/exposure/dbem_spp_list.csv")

# initiate empty df
df <- data.frame()

for (i in 1:length(file_names)) {
  # Read in i'th species file in loop
  df_i <- fread(file_names[i])
  
  df_i <- left_join(df_i, species_names, by = "taxon_key")
  
  # Select only certain variables for certain years and pivot wider
  df_i <- df_i %>%
    mutate(taxon_name = str_to_lower(taxon_name)) %>%
    select(taxon_name, eez_name, ssp, per_change) %>%
    pivot_wider(names_from = ssp, values_from = per_change)
  
  # Combine all species observations into one file
  df <- df %>%
    bind_rows(df_i)
}

# Obtain previous state on dataframe (to get unmatched)
df_preprocessed <- df

# Convert eez variable countries to iso3c codes
for (i in 1:length(df$eez_name)) {
  df$eez_name[i] <- countrycode(df$eez_name[i], origin = 'country.name', destination = 'iso3c')
}

# Rename country variable so it can be joined
df <- df %>%
  rename(eez_iso3c = "eez_name",
         sciname = "taxon_name")



# # See how many countries were not matches
sum(is.na(df$eez_iso3c))

# # Number of countries that properly got matched
length(unique(df$eez_iso3c))

# # Unmatched countries via countrycode
unmatched_countries <- unique(df_preprocessed$eez_name[c(which(is.na(df$eez_iso3c)))])

# # Only keep rows in preprocessed dataset that are unmatched countries
df_preprocessed <- df_preprocessed %>%
  filter(eez_name %in% unmatched_countries)

df_preprocessed %>% distinct(eez_name)
```


```{r preprocess future climatedata}
# Get list of files for future projections on EACH species
file_names <- list.files(path = "../data/species/", pattern = "\\.csv", full.names = TRUE)

# Obtain species lookup key (will be used in loop join)
species_names <- fread("../data/dbem_spp_list.csv")

# Read in eez lat long extents (use to identify eez territories by species distribution in fishbase)
eez_extents <- fread("../data/eez_lat_long_extents.csv")

# initiate empty df
df <- data.frame()

for (i in 1:length(file_names)) {
  # Read in i'th species file in loop
  df_i <- fread(file_names[i])
  
  # rename species variable to taxon_key to a join can work
  df_i <- df_i %>%
    rename(taxon_key = "species")
  
  df_i <- left_join(df_i, species_names, by = "taxon_key")
  
  # Select only certain variables for certain years and pivot wider
  df_i <- df_i %>%
    filter(year %in% c(2030, 2050, 2100)) %>%
    mutate(year_ssp = paste0(year, ssp), sciname = str_to_lower(paste(genus, species))) %>%
    select(sciname, eez_name, year_ssp, mean_per_change) %>%
    pivot_wider(names_from = year_ssp, values_from = mean_per_change)
  
  # Combine all species observations into one file
  df <- df %>%
    bind_rows(df_i)
}

# Obtain previous state on dataframe (to get unmatched)
df_preprocessed <- df

# Convert eez variable countries to iso3c codes
for (i in 1:length(df$eez_name)) {
  df$eez_name[i] <- countrycode(df$eez_name[i], origin = 'country.name', destination = 'iso3c')
}

# Rename country variable so it can be joined
df <- df %>%
  rename(eez_iso3c = "eez_name",
         sciname = "taxon_name")

# # See how many countries were not matches
# sum(is.na(df$eez_iso3c))
# 
# # Number of countries that properly got matched
# length(unique(df$eez_iso3c))
# 
# # Unmatched countries via countrycode
# unmatched_countries <- unique(df_preprocessed$eez_name[c(which(is.na(df$eez_iso3c)))])
# 
# # Only keep rows in preprocessed dataset that are unmatched countries
# df_preprocessed <- df_preprocessed %>%
#   filter(eez_name %in% unmatched_countries)
# 
# df_postprocessed <- df_preprocessed
# 
# # Get country names out of parenthesis with string detects
# for (i in seq_along(df_preprocessed$eez_name)) {
#   
#   if (xor(str_detect(df_preprocessed$eez_name[i], "\\("), str_detect(df_preprocessed$eez_name[i], "Yemen"))) {
#     split_string <- str_split(df_preprocessed$eez_name[i], "\\(")
#     split_string <- str_split(split_string[[1]][2], "\\)")
#     df_postprocessed$eez_name[i] <- split_string[[1]][1]
#   }
#   else if (str_detect(df_preprocessed$eez_name[i], "Yemen")) {
#     df_postprocessed$eez_name[i] <- str_split(df_preprocessed$eez_name[i], "\\ \\(")[[1]][1]
#   }
#   
# }
# 
# # Convert previously unmatched countries to iso3c
# for (i in 1:length(df$eez_name)) {
#   df_postprocessed$eez_name[i] <- countrycode(df_postprocessed$eez_name[i], origin = 'country.name', destination = 'iso3c')
# }
# 
# # Rename country variable so it can be joined
# df_postprocessed <- df_postprocessed %>%
#   rename(eez_iso3c = "eez_name")
# 
# # Add in unmatched countries (now all countries are matched)
# df <- bind_rows(df, df_postprocessed)
```

```{r data cleaning for hdi + consumption data}
# Read in cosnumption data
consumption <- read_parquet("../data/example_consumption_eez_2024_12_06.parquet")
```

```{r exposure (add in future climate data)}
# Get current list of scinames in the future climate data
future_climate_scinames <- unique(df$sciname)

# Group by species and by region so that only species is taken into consideration
df1 <- df %>%
  drop_na() %>%
  group_by(eez_iso3c, sciname) %>%
  summarize(`ssp126` = mean(`ssp126`),
            `ssp585` = mean(`ssp585`))

# Filter out consumption data so it only includes the future names
consumption_future <- consumption %>%
  filter(sciname_hs_modified %in% future_climate_scinames,
         year == 2019)

# Join future data on consumption data
consumption_future <- left_join(consumption_future, df1, by = c("sciname_hs_modified" = "sciname", "eez_iso3c"))

# Pivot dataset to longer to make multiscenario visualization easier
consumption_future <- consumption_future %>%
  pivot_longer(cols = c(`ssp126`,
                        `ssp585`), 
               names_to = "scenario",
               values_to = "future_change_catch")

#Add in variable later
# consumer_foreign_dependencies

# Get % change in stock composition by country
consumer_stock_change <- consumption_future %>% 
  filter(consumer_iso3c != producer_iso3c, # Only include importing countries; drop NAs
         !is.na(live_weight_t),
         !is.na(future_change_catch)) %>%
  mutate(future_change_catch = case_when( # Convert percentage to proportion
    future_change_catch > 0 ~ (future_change_catch / 100) + 1,
    future_change_catch < 0 ~ 1 - ((future_change_catch / 100) * -1), 
    future_change_catch == 0 ~ 1)) %>%
  group_by(consumer_iso3c, scenario, sciname_hs_modified) %>%
  mutate(future_weight_t = live_weight_t * future_change_catch, # Calculate future weight
            change_in_stock = (future_weight_t / live_weight_t)) %>% # Calculate prop in weight change
  group_by(consumer_iso3c, scenario) %>%
  mutate(total_present_weight = sum(live_weight_t)) %>% # Total weight by consuming country / scenario
  ungroup() %>%
  mutate(change_in_stock = case_when( # Convert proportion back to percentage
    change_in_stock > 1 ~ (change_in_stock - 1) * 100,
    change_in_stock < 1 ~ (1 - change_in_stock) * -100,
    change_in_stock == 1 ~ 0
  )) %>%
  group_by(consumer_iso3c, scenario, sciname_hs_modified) %>%
  mutate(pct_influence = live_weight_t / total_present_weight,
         change_in_stock = pct_influence * change_in_stock) %>% # weight stock changes by % live weight for a conusmer has with respect to their total weight (so not all changes in stocks are treated equally (i.e. one change in stock has a high percent, but a very low recorded weight))
  group_by(consumer_iso3c, scenario) %>%
  summarize(change_in_stock = sum(change_in_stock)) %>% # Add weighted % stock changes together per consuming county
  exploreARTIS::add_region("consumer_iso3c", region.col.name = "region") %>%
  filter(!is.na(region))
```

```{r add in sensitivity data}
# Calcualte total foreign weight consumption
domestic_consumption_weights <- consumption %>%
  group_by(consumer_iso3c, year) %>%
  filter(consumer_iso3c == producer_iso3c) %>%
  summarize(domestic_weight = sum(live_weight_t)) %>%
  arrange(consumer_iso3c)

# Calculate total foreign weight consumption
foreign_consumption_weights <- consumption %>%
  group_by(consumer_iso3c, year) %>%
  filter(consumer_iso3c != producer_iso3c) %>%
  summarize(foreign_weight = sum(live_weight_t)) %>%
  arrange(consumer_iso3c)

# Calculate trade dependency
consumer_foreign_dependencies <- foreign_consumption_weights %>%
  filter(consumer_iso3c %in% domestic_consumption_weights$consumer_iso3c) %>%
  left_join(domestic_consumption_weights) %>%
  group_by(consumer_iso3c, year) %>%
  summarize(foreign_dependency = round(foreign_weight /
                                       (foreign_weight +
                                          domestic_weight), 3)) %>%
  exploreARTIS::add_region("consumer_iso3c", region.col.name = "region")


# Find greatest / least changes in foreign dependency
# Largest increase = ISL; largest decrease = NZL
consumer_foreign_dependencies %>%
  # Filter to get only rows for 1996 and 2019
  filter(year %in% c(1996, 2019)) %>%
  # Spread data so that each year gets its own column
  pivot_wider(names_from = year, values_from = foreign_dependency) %>%
  # Calculate the difference between 1996 and 2019
  mutate(diff_2019_1996 = `2019` - `1996`) %>%
  # Select columns as needed
  select(consumer_iso3c, diff_2019_1996) %>%
  arrange(-diff_2019_1996)

# Look at average change in foreign dependency from 2015-2019
foreign_dependency_slopes <- consumer_foreign_dependencies %>%
  split(.$consumer_iso3c) %>% 
  map(~lm(foreign_dependency~year, data = .x)) %>% 
  map_df(broom::tidy, .id = 'consumer_iso3c') %>%
  filter(term == 'year') %>%
  select(consumer_iso3c, "slope" = "estimate") %>%
  mutate(fill_color = case_when(
    slope > 0 ~ "1",
    slope < 0 ~ "0",
    TRUE ~ NA
  )) %>%
  add_region(col = "consumer_iso3c", region.col.name = "region")


foreign_dependency_slopes %>%
  filter(!is.na(region)) %>%
  ggplot(aes(x = reorder(consumer_iso3c, -slope), 
             y = slope, fill = region)) +
  geom_col() +
  theme_minimal_hgrid() +
  theme(axis.text.x = element_blank()) +
  labs(x = "Consuming country", y = "Slope between foreign\ndependency and time", fill = "Region") +
  scale_fill_manual(values = artis_palette(7)) +
  ylim(-0.05, 0.05)

foreign_dependency_slopes %>%
  filter(!is.na(region)) %>%
  ggplot(aes(x = region, y = slope, fill = region)) +
  geom_violin(alpha = 0.5) +
  geom_point() +
  scale_fill_manual(values = artis_palette(7)) +
  theme_minimal_hgrid(12) +
  labs(x = "Consuming country", y = "Slope between foreign\ndependency and time") +
  guides(fill = "none")

# Get greatest increases --> greatest decreases in fd by eez
fd_ordered <- foreign_dependency_slopes %>%
  arrange(-slope) %>%
  pull(consumer_iso3c)

# Create new directory for foreign dependencies
if (!dir.exists("../images/foreign dependency ordered/")) {
  dir.create("../images/foreign dependency ordered/")
}

for (i in fd_ordered) {
  
  # Create image
  img <- consumer_foreign_dependencies %>%
    filter(consumer_iso3c == i) %>%
    ggplot(aes(x = year, y = foreign_dependency)) +
    geom_line() +
    geom_point() +
    theme_minimal_hgrid() +
    labs(x = "", y = "Prop foreign dependency", title = i) +
    theme(plot.title = element_text(hjust = 0.5))
  
  # Save image
  ggsave(paste0("../images/foreign dependency ordered/", which(i == fd_ordered), ".jpg"), plot = img, device = "jpeg", height = 4, width = 6, units = "in")
}


# Read in FAO consumer data
fao_food <- read_csv("../data/FoodBalanceSheets_E_All_Data/FoodBalanceSheets_E_All_Data.csv")

# Convert FAO data to long format
fao_food_long <- fao_food %>%
  pivot_longer(cols = c("Y2010", "Y2011", "Y2012", "Y2013", "Y2014", 
               "Y2015", "Y2016", "Y2017", "Y2018", "Y2019"), names_to = "year") %>%
  mutate(year = str_replace(year, "Y", ""))

# Extract FAO animal protein totals
aquatic_animal_proteins <- fao_food_long %>%
  filter(Element == "Protein supply quantity (t)",
         Item %in% c("Aquatic Animals, Others", "Cephalopods",
                     "Crustaceans", "Demersal Fish", "Fish, Seafood",
                     "Freshwater Fish", "Marine Fish, Other", "Meat, Aquatic Mammals",
                     "Molluscs, Other"),) %>%
  mutate(iso3c = countrycode(Area, origin = 'country.name', destination = 'iso3c')) %>%
  relocate(iso3c, .before = "Area") %>%
  group_by(iso3c, year) %>%
  summarize(a_a_protein = sum(value, na.rm = TRUE)) %>%
  ungroup()

total_protein <- fao_food_long %>%
  filter(Element == "Protein supply quantity (t)",
         Item == "Animal Products") %>%
  mutate(iso3c = countrycode(Area, origin = 'country.name', destination = 'iso3c')) %>%
  relocate(iso3c, .before = "Area") %>%
  group_by(iso3c, year) %>%
  summarize(t_p = sum(value, na.rm = TRUE)) %>%
  ungroup()

# Produce proportions aquatic animal protein of total conusmed protein
fao_prop_imports <- left_join(aquatic_animal_proteins, total_protein) %>%
  group_by(iso3c, year) %>%
  summarize(prop_aquatic_animal = a_a_protein / t_p) %>%
  mutate(year = as.numeric(year)) %>%
  exploreARTIS::add_region("iso3c", region.col.name = "region")

# Create a list of years for which you have files (FAO data only goes back to 2010)
years <- 2010:2019
consumption_full <- data.frame()

# Use a loop to read the files and bind them together
for (i in years) {
  # Generate the filename
  file_name <- paste0("../data/full consumption/consumption/consumption_midpoint_HS96_", as.character(i), ".csv")
  # Read the CSV file
  yearly_data <- read_csv(file_name)
  consumption_full <- bind_rows(consumption_full, yearly_data)
}

# Calculate proportion of consumed materials from different habitats and methods
habitat_method_props <- consumption_full %>%
  group_by(year, consumer_iso3c, habitat, method) %>%
  summarize(total_group_catch = sum(consumption_live_t)) %>%
  filter(!habitat == "unknown" | 
         !method == "unknown") %>%
  group_by(year, consumer_iso3c) %>%
  mutate(total_catch = sum(total_group_catch)) %>%
  group_by(year, consumer_iso3c, habitat, method) %>%
  summarize(prop_consumption = total_group_catch / total_catch) %>%
  ungroup()

# Join artis and fao food balance sheet data (combines habitat/method props to prop animal protein imports byt fao)
artis_fao_fbb <- left_join(habitat_method_props, fao_prop_imports, by = c("consumer_iso3c" = "iso3c", "year"))

# How important is marine capture on countries' animal sourced protein supply?
supply_importance <- artis_fao_fbb %>%
  group_by(year, consumer_iso3c) %>%
  mutate(importance_on_protein_cons = prop_consumption * prop_aquatic_animal) %>%
  filter(!is.na(region)) %>%
    filter(habitat == "marine",
         method == "capture", .keep_all = TRUE)
```


```{r process adaptive capacity data}
# Get ARTIS consuming countries (For identifying data coverage)
consuming_countries <- consumption %>%
  filter(consumer_iso3c != producer_iso3c) %>%
  distinct(consumer_iso3c) %>%
  mutate(artis = 1)

country_coverage <- function(data2, join_by = "") {
  # Full join ARTIS countries + AC countries
  data <- full_join(consuming_countries, data2 %>% 
            mutate(gdp_coverage = 1), 
            by = c("consumer_iso3c" = join_by)) %>%
  filter(is.na(gdp_coverage) & artis == 1)
  
  # Look at which countries are missing
  missing_countries <- data %>%
    pull(consumer_iso3c)
  
  return(missing_countries)
}

##########
# ASSETS #
##########

# sanitation
sanitation <- read_csv("../data/adaptive capacity/assets/sanitation.csv")

sanitation_clean <- sanitation %>%
  filter(Indicator_Code == "SH_STA_BASS_ZS", Time_Period == 2019)

a <- country_coverage(sanitation_clean, join_by = "Geography_Code")

# gdp
gdp <- read_csv("../data/adaptive capacity/assets/gdp.csv")

gdp_clean <- gdp %>%
  select(`Country Code`, `2019`) %>%
  filter(!is.na(`2019`))

b <- country_coverage(gdp_clean, join_by = "Country Code")

# trade standardized by gdp
trade_gdp <- read_csv("../data/adaptive capacity/assets/trade_gdp.csv")

trade_gdp_clean <- trade_gdp %>%
  filter(`Indicator Code` == "NE.TRD.GNFS.ZS") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

c <- country_coverage(trade_gdp_clean, join_by = "Country Code")



###############
# FLEXIBILITY #
###############

# life expectancy
life_expectancy <- read_csv("../data/adaptive capacity/flexibility/life_expectancy_at_birth.csv")

life_expectancy_clean <- life_expectancy %>%
  filter(`Indicator Code` == "SP.DYN.LE00.IN") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

d <- country_coverage(life_expectancy_clean, join_by = "Country Code")

# supermarkets per 100000
supermarkets <- read_csv("../data/adaptive capacity/flexibility/supermarkets_per_100000.csv")

supermarkets_clean <- supermarkets %>%
  mutate(iso3c = countrycode(Region, origin = 'country.name', destination = 'iso3c')) %>%
  select(iso3c, `2019`) %>%
  filter(!is.na(2019))

e <- country_coverage(supermarkets_clean, join_by = "iso3c")

# prop labor force
total_labor_force <- read_csv("../data/adaptive capacity/flexibility/total_labor_force.csv")
total_population <- read_csv("../data/adaptive capacity/flexibility/total_population.csv")

total_population_clean <- total_population %>%
  select(`Country Code`, `2019`) %>%
  rename(total_pop_2019 = "2019")

prop_population_clean <- left_join(total_labor_force, total_population_clean, by = "Country Code") %>%
  select(`Country Code`, `2019`, total_pop_2019) %>%
  mutate(prop_labor = `2019` / total_pop_2019) %>%
  filter(!is.na(prop_labor))

f <- country_coverage(prop_population_clean, join_by = "Country Code")



############
# LEARNING #
############

# Jessica's data
# avg_education <- read_csv("../data/adaptive capacity/all_national_indicators.csv")

# # mean years schooling data
# mean_years_schooling <- read_csv("../data/adaptive capacity/learning/mean_years_schooling.csv")
# # 
# mean_years_schooling_clean <- mean_years_schooling %>%
#   filter(Year == 2015) %>%
#   filter(!is.na(avg_years_education_15_to_64))
# 
# g <- country_coverage(mean_years_schooling_clean, join_by = "Code")

# Human capital index
hci <- read_csv("../data/adaptive capacity/learning/HCIData.csv")

hci_clean <- hci %>%
  filter(`Indicator Name` == "Human Capital Index (HCI) (scale 0-1)") %>%
  select(`Country Code`, `2018`) %>%
  filter(!is.na(`2018`))
  
h <- country_coverage(hci_clean, join_by = "Country Code")

#######################
# SOCIAL ORGANIZATION #
#######################

# government effectiveness
government_effectiveness <- read_csv("../data/adaptive capacity/social organization/government_effectiveness_percentile.csv")

government_effectiveness_clean <- government_effectiveness %>%
  filter(`Indicator ID` == "WB.WWGI.GE.PER.RNK") %>%
  select(`Economy ISO3`,`2019`) %>%
  filter(!is.na(`2019`))

i <- country_coverage(government_effectiveness_clean, join_by = "Economy ISO3")

# Food safety capacity
fsc <- read_csv("../data/adaptive capacity/social organization/food-systems-dashboard-2025-03-04.csv")

fsc_clean <- fsc %>%
  filter(`Start Year` == 2019 | `End Year` == 2019)

j <- country_coverage(fsc_clean, join_by = "ISO3")

# Rule of law
rol <- read_csv("../data/adaptive capacity/social organization/WB-WWGI.csv")

rol_clean <- rol %>% 
  filter(Indicator == "Rule of Law: Percentile Rank") %>%
  select(`Economy ISO3`, `Indicator`, `2019`)

k <- country_coverage(rol_clean, join_by = "Economy ISO3")

# Count total number of ARTIS countries missing across adaptive capacity sources
length(unique(c(a,b,c,d,e,f,h,i,j,k)))

# assign missing countries to vector
missing_artis_ac_countries <- unique(c(a,b,c,d,e,f,h,i,j,k))

# Look at variable coverage across datasets for each country
 variable_coverage <- consuming_countries %>%
   select(-artis) %>%
   mutate(a = case_when(consumer_iso3c %in% a ~ 1, TRUE ~ 0),
          b = case_when(consumer_iso3c %in% b ~ 1, TRUE ~ 0),
          c = case_when(consumer_iso3c %in% c ~ 1, TRUE ~ 0),
          d = case_when(consumer_iso3c %in% d ~ 1, TRUE ~ 0),
          e = case_when(consumer_iso3c %in% e ~ 1, TRUE ~ 0),
          f = case_when(consumer_iso3c %in% f ~ 1, TRUE ~ 0),
          h = case_when(consumer_iso3c %in% h ~ 1, TRUE ~ 0),
          i = case_when(consumer_iso3c %in% i ~ 1, TRUE ~ 0),
          j = case_when(consumer_iso3c %in% j ~ 1, TRUE ~ 0),
          k = case_when(consumer_iso3c %in% k ~ 1, TRUE ~ 0)) %>%
   pivot_longer(cols = c(a,b,c,d,e,f,h,i,j,k)) %>%
   rename(ac_var_name = "name",
          present_absent = "value") %>%
   filter(!str_detect(consumer_iso3c, "NEI")) %>%
   mutate(ac_var_name = case_when(
     ac_var_name == "a" ~ "Access to sanitation",
     ac_var_name == "b" ~ "GDP",
     ac_var_name == "c" ~ "Prop trade of GDP",
     ac_var_name == "d" ~ "Life expectancy at birth",
     ac_var_name == "e" ~ "Supermarkets per 100,000",
     ac_var_name == "f" ~ "Prop population in labor force",
     ac_var_name == "h" ~ "Human capital index",
     ac_var_name == "i" ~ "Government effectivenes",
     ac_var_name == "j" ~ "Food safety capacity",
     ac_var_name == "k" ~ "Rule of law"
   ))

# Create a heatmap of the variable coverage
variable_coverage %>%
  ggplot(aes(y = ac_var_name, x = consumer_iso3c, fill = factor(present_absent))) +
  geom_tile() +
  scale_fill_manual(values = c("white", "#FF0000")) +
  guides(fill = "none") +
  theme_cowplot() +
  theme(axis.text.x = element_blank()) +
  labs(x = "Consuming country", y = "Adaptive capacity variable")

# Get whether an artis country was missing across # of datasets
missing_artis_ac_countries <- data.frame(consumer_iso3c = c(a,b,c,d,e,f,h,i,j,k)) %>%
  count(consumer_iso3c) %>%
  rename(artis = "n") %>%
  filter(consumer_iso3c != "NEI")

# Show which artis countries are covered by artis / which are not
ac_coverage <- bind_rows(consuming_countries %>%
                           mutate(artis = 0) %>%
                           filter(!consumer_iso3c %in% missing_artis_ac_countries), 
                         missing_artis_ac_countries)

ac_coverage %>%
  mutate(artis = as.numeric(artis)) %>%
  filter(artis != 0) %>%
  ggplot(aes(x = artis)) +
  geom_histogram(boundary = 0, binwidth = 1, color = "black") +
  theme_cowplot(15) +
  labs(x = "# AC datasets ARTIS\nconsuming country\nis missing from",
       y = "# countries")

# Calculate number of datasets countries are missing from
variable_coverage %>%
  group_by(consumer_iso3c) %>%
  summarize(num_datasets_missing_from = sum(present_absent)) %>%
  arrange(-num_datasets_missing_from) %>%
  filter(!str_detect(consumer_iso3c, "NEI")) %>%
  write.csv("../data/adaptive capacity/ac_coverage.csv")

variable_coverage %>%
  group_by(ac_var_name) %>%
  summarize(num_countries_missing = sum(present_absent)) %>%
  arrange(-num_countries_missing)
```

```{r calculate risk}
# Prepare AC data so that it can be joined

# Assets
gdp_clean <- gdp_clean %>%
  rename(gdp = "2019", consumer_iso3c = "Country Code")

trade_gdp_clean <- trade_gdp_clean %>%
  rename(gdp_trade = "2019", consumer_iso3c = "Country Code")
  
sanitation_clean <- sanitation_clean %>%
  rename(sanitation = "Value", consumer_iso3c = "Geography_Code") %>%
  select(sanitation, consumer_iso3c)


# Flexibility
supermarkets_clean <- supermarkets_clean %>%
  rename(supermarkets = "2019", consumer_iso3c = "iso3c")

life_expectancy_clean <- life_expectancy_clean %>%
  rename(life_expectancy = "2019", consumer_iso3c = "Country Code")

prop_population_clean <- prop_population_clean %>%
  rename(consumer_iso3c = "Country Code") %>%
  select(consumer_iso3c, prop_labor)

# Learning

# No longer using mean years schooling
# mean_years_schooling_clean <- mean_years_schooling_clean %>%
#   rename(avg_yrs_educ = "avg_years_education_15_to_64", consumer_iso3c = "Code") %>%
# select(consumer_iso3c, avg_yrs_educ)

hci_clean <- hci_clean %>%
  rename(hci = "2018", consumer_iso3c = "Country Code")


# Social organization
government_effectiveness_clean <- government_effectiveness_clean %>%
  rename(gov_effectiveness = "2019", consumer_iso3c = "Economy ISO3")

fsc_clean <- fsc_clean %>%
  rename(fsc = "Value", consumer_iso3c = "ISO3") %>%
  select(consumer_iso3c, fsc)
  

rol_clean <- rol_clean %>%
  rename(rol = "2019", consumer_iso3c = "Economy ISO3") %>%
  select(consumer_iso3c, rol)

# A LOT OF JOINS
e_s_ac_data <- left_join(gdp_clean, trade_gdp_clean) %>%
  left_join(sanitation_clean) %>%
  left_join(supermarkets_clean) %>%
  left_join(life_expectancy_clean) %>%
  left_join(prop_population_clean) %>%
  left_join(hci_clean) %>%
  left_join(government_effectiveness_clean) %>%
  left_join(fsc_clean) %>%
  left_join(rol_clean) %>%
  right_join(consumer_stock_change %>% # Add in exposure data
               select(consumer_iso3c, scenario, change_in_stock), by = "consumer_iso3c") %>%
  left_join(supply_importance %>% # Add in fao sensitivity data
              filter(year == 2019,
                     habitat == "marine",
                     method == "capture") %>%
              ungroup() %>%
              select(consumer_iso3c, importance_on_protein_cons),
            by = "consumer_iso3c") %>%
  left_join(consumer_foreign_dependencies %>% # Add in foreign dependency sensitivity
              filter(year == 2019) %>%
              ungroup() %>%
              select(consumer_iso3c, foreign_dependency),
            by = "consumer_iso3c")

# Save joined data to output folder
write_parquet(e_s_ac_data, "../output/e_s_ac_data.parquet")
```


