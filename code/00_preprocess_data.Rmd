---
title: "Seafood Analysis"
author: "Connor Quiroz"
date: "2024-11-15"
output: html_document
---

# Setup / Load in Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# General data cleaning + visualization + analysis packages
library(tidyverse)
library(ggformula)
library(countrycode)
library(data.table)
library(arrow)
library(cowplot)
library(RColorBrewer)

# Map creation
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)

# Load in packages needed for ARTIS
library(devtools)
library(tidytext)
# devtools::install_github("davidsjoberg/ggsankey")
library(ggsankey)
# devtools::install_github("Seafood-Globalization-Lab/exploreARTIS@v1.0.0", dependencies = TRUE)
library(exploreARTIS)
```

# Data Cleaning

```{r new preprocess future climate data}
# file_names <- list.files(path = "../data/exposure/mcp_per_change/mcp_per_change/", pattern = "\\.csv", full.names = TRUE)
# 
# # Obtain species lookup key (will be used in loop join)
# species_names <- fread("../data/exposure/dbem_spp_list.csv")
# 
# # initiate empty df
# df <- data.frame()
# 
# for (i in 1:length(file_names)) {
#   # Read in i'th species file in loop
#   df_i <- fread(file_names[i])
#   
#   df_i <- left_join(df_i, species_names, by = "taxon_key")
#   
#   # Select only certain variables for certain years and pivot wider
#   df_i <- df_i %>%
#     mutate(taxon_name = str_to_lower(taxon_name)) %>%
#     select(taxon_name, eez_name, ssp, per_change) %>%
#     pivot_wider(names_from = ssp, values_from = per_change)
#   
#   # Combine all species observations into one file
#   df <- df %>%
#     bind_rows(df_i)
# }
# 
# # Obtain previous state on dataframe (to get unmatched)
# df_preprocessed <- df
# 
# # Convert eez variable countries to iso3c codes
# for (i in 1:length(df$eez_name)) {
#   df$eez_name[i] <- countrycode(df$eez_name[i], origin = 'country.name', destination = 'iso3c')
# }
# 
# # Rename country variable so it can be joined
# df <- df %>%
#   rename(eez_iso3c = "eez_name",
#          sciname = "taxon_name")
# 
# # Write joined future cimate data to .csv
# write_csv(df, "../output/future_climate_joined.csv")
# 
# # # See how many countries were not matches
# sum(is.na(df$eez_iso3c))
# 
# # # Number of countries that properly got matched
# length(unique(df$eez_iso3c))
# 
# # # Unmatched countries via countrycode
# unmatched_countries <- unique(df_preprocessed$eez_name[c(which(is.na(df$eez_iso3c)))])
# 
# # # Only keep rows in preprocessed dataset that are unmatched countries
# df_preprocessed <- df_preprocessed %>%
#   filter(eez_name %in% unmatched_countries)
# 
# # Territories that were not matched via countrycode (Tokelau & Svalbard Isl.)
# df_preprocessed %>% distinct(eez_name)

####################################

# # Get country names out of parenthesis with string detects
# for (i in seq_along(df_preprocessed$eez_name)) {
#   
#   if (xor(str_detect(df_preprocessed$eez_name[i], "\\("), str_detect(df_preprocessed$eez_name[i], "Yemen"))) {
#     split_string <- str_split(df_preprocessed$eez_name[i], "\\(")
#     split_string <- str_split(split_string[[1]][2], "\\)")
#     df_postprocessed$eez_name[i] <- split_string[[1]][1]
#   }
#   else if (str_detect(df_preprocessed$eez_name[i], "Yemen")) {
#     df_postprocessed$eez_name[i] <- str_split(df_preprocessed$eez_name[i], "\\ \\(")[[1]][1]
#   }
#   
# }
# 
# # Convert previously unmatched countries to iso3c
# for (i in 1:length(df$eez_name)) {
#   df_postprocessed$eez_name[i] <- countrycode(df_postprocessed$eez_name[i], origin = 'country.name', destination = 'iso3c')
# }
# 
# # Rename country variable so it can be joined
# df_postprocessed <- df_postprocessed %>%
#   rename(eez_iso3c = "eez_name")
# 
# # Add in unmatched countries (now all countries are matched)
# df <- bind_rows(df, df_postprocessed)
```

```{r data cleaning for hdi + consumption data}
# Read in cosnumption data
consumption <- read_parquet("../data/example_consumption_eez_2024_12_06.parquet") %>%
  mutate(sciname_hs_modified = case_when(
    is.na(sciname_hs_modified) ~ sciname,
    TRUE ~ sciname_hs_modified
  )) # Get rid of NA scinames

# Read in sciname data (for joining to scinames of future climate)
sciname <- read_csv("../data/sciname.csv")
```

```{r disaggregate future climate measurements}
# Read in future climate data
df <- read_csv("../output/future_climate_joined.csv")

# Group by species and by region so that only species is taken into consideration
df1 <- df %>%
  drop_na() %>%
  group_by(eez_iso3c, sciname) %>%
  summarize(`ssp126` = mean(`ssp126`),
            `ssp585` = mean(`ssp585`))

sciname_taxa <- sciname %>% 
  mutate(taxa_level = case_when(
    sciname == kingdom ~ "kingdom",
    sciname == phylum ~ "phylum",
    sciname == superclass ~ "superclass",
    sciname == class ~ "class",
    sciname == order ~ "order",
    sciname == family ~ "family",
    sciname == subfamily ~ "subfamily",
    sciname == genus ~ "genus",
    str_detect(sciname, " ") ~ "species"
  )) %>%
  mutate(species = case_when(
    str_count(sciname, " ") == 1 ~ word(sciname, 2),
    TRUE ~ NA_character_
  )) %>% # Add species column name
  relocate(species, .before = genus) %>% 
  select(-common_name, -isscaap)

# Filter out consumption data so it only includes the future names
consumption_future <- consumption %>%
  filter(year == 2019)

# Join consumption to sciname data
consumption_sciname <- left_join(consumption_future, sciname_taxa, by = c("sciname_hs_modified" = "sciname"))

# Join consumption/sciname by sciname / eez
test_data <- left_join(consumption_sciname, df1, by = c("eez_iso3c", "sciname_hs_modified" = "sciname"))

# Create function to average across across every future climate sciname for every taxa level names (e.g., order, class, genus)
compute_taxa_averages <- function(df, tax_level) {
  df %>%
    filter(!is.na(ssp126) | !is.na(ssp585)) %>%  # Keep only true species
    group_by(eez_iso3c, !!sym(tax_level)) %>%    # Group by EEZ & chosen tax level
    summarise(
      avg_ssp126 = mean(ssp126, na.rm = TRUE),
      avg_ssp585 = mean(ssp585, na.rm = TRUE),
      .groups = "drop"  # Prevent unexpected grouping behavior
    )
}

# Compute averages across all taxa levels
averages_genus <- compute_taxa_averages(test_data, "genus") %>%
  rename(taxa_name = genus) %>%
  mutate(taxa_level = "genus")

averages_subfamily <- compute_taxa_averages(test_data, "subfamily") %>%
  rename(taxa_name = subfamily) %>%
  mutate(taxa_level = "subfamily")

averages_family <- compute_taxa_averages(test_data, "family") %>%
  rename(taxa_name = family) %>%
  mutate(taxa_level = "family")

averages_order <- compute_taxa_averages(test_data, "order") %>%
  rename(taxa_name = order) %>%
  mutate(taxa_level = "order")

averages_class <- compute_taxa_averages(test_data, "class") %>%
  rename(taxa_name = class) %>%
  mutate(taxa_level = "class")

averages_phylum <- compute_taxa_averages(test_data, "phylum") %>%
  rename(taxa_name = phylum) %>%
  mutate(taxa_level = "phylum")

# Combine all aggregated results into a single lookup table:
lookup_table <- bind_rows(averages_genus, averages_subfamily, averages_family, averages_order, averages_class, averages_phylum)


# Currently: averaging future climate data to higher values adds ~ 300,000 rows
interpolated_future_data <- left_join(test_data, lookup_table, by = c("eez_iso3c", "sciname_hs_modified" = "taxa_name", "taxa_level")) %>%
  mutate(
    ssp126 = if_else(is.na(ssp126), avg_ssp126, ssp126), # Interpolate non-true species to averages created from original future climate data based on true species
    ssp585 = if_else(is.na(ssp585), avg_ssp585, ssp585)
  ) %>%
  select(-avg_ssp126, -avg_ssp585)
  
# Just a check - not all the scinames in Juliano's future climate data join to artis because they are organized by sciname and eez. So not every sciname will join to the artis sciname because while Juliano's sciname might be in artis, it might not be in the same eez too.
  full_join(
    consumption_sciname %>% mutate(artis = TRUE),
    df1 %>%
      mutate(fcd = TRUE),
    by = c("eez_iso3c", "sciname_hs_modified" = "sciname")
  ) %>%
    filter(fcd == TRUE) %>%
    ungroup() %>%
    filter(is.na(artis), fcd == TRUE)
  
# Remove previous objects to keep data usage small
rm(consumption_sciname, sciname_taxa, consumption,
   averages_class, averages_family, averages_genus,
   averages_order, averages_phylum, averages_subfamily,
   df, lookup_table, sciname, sciname_taxa, test_data)
gc() # Garbage collection to clean up storage

# Find the sum of the interpolated scinames' live_weights
interpolated_future_data %>% 
  filter(!is.na(ssp126)) %>% distinct(sciname_hs_modified)


# Just Juliano's data
interpolated_future_data %>% 
  filter(str_detect(sciname_hs_modified, " "), !is.na(ssp126)) %>% 
  summarize(sum_live_weight_t = sum(live_weight_t)) 


# No values
interpolated_future_data %>% 
  filter(is.na(ssp126)) %>% 
  group_by(sciname_hs_modified, eez_iso3c) %>% 
  summarize(sum_live_weight_t = sum(live_weight_t)) %>%
  arrange(-sum_live_weight_t)

unique(df1$sciname) %>% length()

consumption_future %>% distinct(sciname_hs_modified)

# consumption_future %>%
#   left_join(sciname, by = c("sciname_hs_modfied" = "sciname")) %>%
#   filter(class == "actinopterygii",
#          is.na(ssp126)) 
```


```{r derive exposure measurements via disaggregated future climate data}
### BRINGING IN interpolated_future_data from 98_Testing_Future_Catch_Disaggregation ###

# Join future data on consumption data
consumption_future <- left_join(interpolated_future_data, df1, by = c("sciname_hs_modified" = "sciname", "eez_iso3c"))

# Pivot dataset to longer to make multiscenario visualization easier
consumption_future <- interpolated_future_data %>%
  pivot_longer(cols = c(`ssp126`,
                        `ssp585`), 
               names_to = "scenario",
               values_to = "future_change_catch")

#Add in variable later
# consumer_foreign_dependencies


# NOTE: Commenting out first filter will give the entire consumption portfolio. Commenting out the second filter will give only imports.

# Get % change in stock composition by country
consumer_stock_change_pre <- consumption_future %>% 
  filter(consumer_iso3c != producer_iso3c, # Only include importing countries; drop NAs
         !is.na(live_weight_t),
         !is.na(future_change_catch)) %>%
  # filter(!is.na(live_weight_t),
  #        !is.na(future_change_catch)) %>%
  mutate(future_change_catch = case_when( # Convert percentage to proportion
    future_change_catch > 0 ~ (future_change_catch / 100) + 1,
    future_change_catch < 0 ~ 1 - ((future_change_catch / 100) * -1), 
    future_change_catch == 0 ~ 1)) %>%
  # group_by(consumer_iso3c, scenario, sciname_hs_modified) %>%
  mutate(change_in_stock = live_weight_t * future_change_catch)
  
# Use future weights to calculate % change in weight by country
consumer_stock_change <- consumer_stock_change_pre %>% 
  group_by(consumer_iso3c, scenario) %>%
    summarize(change_in_stock = sum(change_in_stock),
              live_weight_t = sum(live_weight_t)) %>%
    mutate(pct_change = 100 * ((change_in_stock - live_weight_t) / live_weight_t))

# Write to csv
write_csv(consumer_stock_change, "../output/consumer_stock_change.csv")

# Remove previous objects to keep data usage small
rm(df1, interpolated_future_data, consumer_stock_change_pre)
gc() # Garbage collection to clean up storage
```

```{r delete}
# test_country <- countries_with_both$consumer_iso3c[1]
# test_scenario <- countries_with_both$scenario[1]
# 
# # Run your exact pipeline on this one country - with domestic
# with_domestic_test <- consumption_future %>% 
#   filter(consumer_iso3c == test_country, scenario == test_scenario,
#          !is.na(live_weight_t), !is.na(future_change_catch)) %>%
#   mutate(future_change_catch = case_when(
#     future_change_catch > 0 ~ (future_change_catch / 100) + 1,
#     future_change_catch < 0 ~ 1 - ((future_change_catch / 100) * -1), 
#     future_change_catch == 0 ~ 1)) %>%
#   mutate(change_in_stock = live_weight_t * future_change_catch) %>%
#   group_by(consumer_iso3c, scenario) %>%
#   summarize(change_in_stock = sum(change_in_stock),
#             live_weight_t = sum(live_weight_t), .groups = 'drop')
# 
# # Run pipeline - imports only  
# imports_only_test <- consumption_future %>% 
#   filter(consumer_iso3c == test_country, scenario == test_scenario,
#          consumer_iso3c != producer_iso3c,
#          !is.na(live_weight_t), !is.na(future_change_catch)) %>%
#   mutate(future_change_catch = case_when(
#     future_change_catch > 0 ~ (future_change_catch / 100) + 1,
#     future_change_catch < 0 ~ 1 - ((future_change_catch / 100) * -1), 
#     future_change_catch == 0 ~ 1)) %>%
#   mutate(change_in_stock = live_weight_t * future_change_catch) %>%
#   group_by(consumer_iso3c, scenario) %>%
#   summarize(change_in_stock = sum(change_in_stock),
#             live_weight_t = sum(live_weight_t), .groups = 'drop')
# 
# print("With domestic:")
# print(with_domestic_test)
# print("Imports only:")
# print(imports_only_test)
# print("Difference in live_weight_t:")
# print(with_domestic_test$live_weight_t - imports_only_test$live_weight_t)
```


```{r add in sensitivity data}
# Read in supply importance data
supply_importance <- read_csv("../data/sensitivity/supply_importance.csv")

# Calculate foreign dependency
consumer_foreign_dependencies <- supply_importance %>%
  filter(consumption_source == "foreign") %>%
  group_by(consumer_iso3c, year) %>%
  summarize(foreign_dependency = sum(prop_consumption)) %>%
exploreARTIS::add_region(col = "consumer_iso3c", region.col.name = "region")

# Calculate aquatic animal reliance
aa_reliance <- supply_importance %>% # Add in fao sensitivity data
              filter(year == 2019,
                     habitat == "marine",
                     method == "capture") %>%
              group_by(consumer_iso3c) %>% # Sum across domestic / foreign consumption
              summarize(aa_reliance_pct = sum(aa_reliance_pct)) %>%
              ungroup()

# Remove previous objects to keep data usage small
rm(supply_importance)
gc() # Garbage collection to clean up storage
```


```{r process adaptive capacity data}
# Get ARTIS consuming countries (For identifying data coverage)
# changed consumption to consumption_future
consuming_countries <- consumption_future %>%
  filter(consumer_iso3c != producer_iso3c) %>%
  distinct(consumer_iso3c) %>%
  mutate(artis = 1)

country_coverage <- function(data2, join_by = "") {
  # Full join ARTIS countries + AC countries
  data <- full_join(consuming_countries, data2 %>% 
            mutate(gdp_coverage = 1), 
            by = c("consumer_iso3c" = join_by)) %>%
  filter(is.na(gdp_coverage) & artis == 1)
  
  # Look at which countries are missing
  missing_countries <- data %>%
    pull(consumer_iso3c)
  
  return(missing_countries)
}

##########
# ASSETS #
##########

# sanitation
sanitation <- read_csv("../data/adaptive capacity/assets/sanitation.csv")

sanitation_clean <- sanitation %>%
  filter(Indicator_Code == "SH_STA_BASS_ZS", Time_Period == 2019)

a <- country_coverage(sanitation_clean, join_by = "Geography_Code")

# gdp
gdp <- read_csv("../data/adaptive capacity/assets/gdp.csv")

gdp_clean <- gdp %>%
  select(`Country Code`, `2019`) %>%
  filter(!is.na(`2019`))

b <- country_coverage(gdp_clean, join_by = "Country Code")

# trade standardized by gdp
trade_gdp <- read_csv("../data/adaptive capacity/assets/trade_gdp.csv")

trade_gdp_clean <- trade_gdp %>%
  filter(`Indicator Code` == "NE.TRD.GNFS.ZS") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

c <- country_coverage(trade_gdp_clean, join_by = "Country Code")



###############
# FLEXIBILITY #
###############

# life expectancy
life_expectancy <- read_csv("../data/adaptive capacity/flexibility/life_expectancy_at_birth.csv")

life_expectancy_clean <- life_expectancy %>%
  filter(`Indicator Code` == "SP.DYN.LE00.IN") %>%
  select(`Country Code`,`2019`) %>%
  filter(!is.na(`2019`))

d <- country_coverage(life_expectancy_clean, join_by = "Country Code")

# supermarkets per 100000
supermarkets <- read_csv("../data/adaptive capacity/flexibility/supermarkets_per_100000.csv")

supermarkets_clean <- supermarkets %>%
  mutate(iso3c = countrycode(Region, origin = 'country.name', destination = 'iso3c')) %>%
  select(iso3c, `2019`) %>%
  filter(!is.na(2019))

e <- country_coverage(supermarkets_clean, join_by = "iso3c")

# prop labor force
total_labor_force <- read_csv("../data/adaptive capacity/flexibility/total_labor_force.csv")
total_population <- read_csv("../data/adaptive capacity/flexibility/total_population.csv")

total_population_clean <- total_population %>%
  select(`Country Code`, `2019`) %>%
  rename(total_pop_2019 = "2019")

prop_population_clean <- left_join(total_labor_force, total_population_clean, by = "Country Code") %>%
  select(`Country Code`, `2019`, total_pop_2019) %>%
  mutate(prop_labor = `2019` / total_pop_2019) %>%
  filter(!is.na(prop_labor))

f <- country_coverage(prop_population_clean, join_by = "Country Code")



############
# LEARNING #
############

# Jessica's (UNESCO) data - similar coverage to mean years schooling - fsc had higher data coverage over both World Bank and UNESCO

# avg_education <- read_csv("../data/adaptive capacity/all_national_indicators.csv")

# # mean years schooling data
# mean_years_schooling <- read_csv("../data/adaptive capacity/learning/mean_years_schooling.csv")
# # 
# mean_years_schooling_clean <- mean_years_schooling %>%
#   filter(Year == 2015) %>%
#   filter(!is.na(avg_years_education_15_to_64))
# 
# g <- country_coverage(mean_years_schooling_clean, join_by = "Code")

# Human capital index
hci <- read_csv("../data/adaptive capacity/learning/HCIData.csv")

hci_clean <- hci %>%
  filter(`Indicator Name` == "Human Capital Index (HCI) (scale 0-1)") %>%
  select(`Country Code`, `2018`) %>%
  filter(!is.na(`2018`))
  
h <- country_coverage(hci_clean, join_by = "Country Code")

#######################
# SOCIAL ORGANIZATION #
#######################

# government effectiveness
government_effectiveness <- read_csv("../data/adaptive capacity/social organization/government_effectiveness_percentile.csv")

government_effectiveness_clean <- government_effectiveness %>%
  filter(`Indicator ID` == "WB.WWGI.GE.PER.RNK") %>%
  select(`Economy ISO3`,`2019`) %>%
  filter(!is.na(`2019`))

i <- country_coverage(government_effectiveness_clean, join_by = "Economy ISO3")

# Food safety capacity
fsc <- read_csv("../data/adaptive capacity/social organization/food-systems-dashboard-2025-03-04.csv")

fsc_clean <- fsc %>%
  filter(`Start Year` == 2019 | `End Year` == 2019)

j <- country_coverage(fsc_clean, join_by = "ISO3")

# Rule of law
rol <- read_csv("../data/adaptive capacity/social organization/WB-WWGI.csv")

rol_clean <- rol %>% 
  filter(Indicator == "Rule of Law: Percentile Rank") %>%
  select(`Economy ISO3`, `Indicator`, `2019`)

k <- country_coverage(rol_clean, join_by = "Economy ISO3")

# Count total number of ARTIS countries missing across adaptive capacity sources
length(unique(c(a,b,c,d,e,f,h,i,j,k)))

# assign missing countries to vector
missing_artis_ac_countries <- unique(c(a,b,c,d,e,f,h,i,j,k))

# Look at variable coverage across datasets for each country
 variable_coverage <- consuming_countries %>%
   select(-artis) %>%
   mutate(a = case_when(consumer_iso3c %in% a ~ 1, TRUE ~ 0),
          b = case_when(consumer_iso3c %in% b ~ 1, TRUE ~ 0),
          c = case_when(consumer_iso3c %in% c ~ 1, TRUE ~ 0),
          d = case_when(consumer_iso3c %in% d ~ 1, TRUE ~ 0),
          e = case_when(consumer_iso3c %in% e ~ 1, TRUE ~ 0),
          f = case_when(consumer_iso3c %in% f ~ 1, TRUE ~ 0),
          h = case_when(consumer_iso3c %in% h ~ 1, TRUE ~ 0),
          i = case_when(consumer_iso3c %in% i ~ 1, TRUE ~ 0),
          j = case_when(consumer_iso3c %in% j ~ 1, TRUE ~ 0),
          k = case_when(consumer_iso3c %in% k ~ 1, TRUE ~ 0)) %>%
   pivot_longer(cols = c(a,b,c,d,e,f,h,i,j,k)) %>%
   rename(ac_var_name = "name",
          present_absent = "value") %>%
   filter(!str_detect(consumer_iso3c, "NEI")) %>%
   mutate(ac_var_name = case_when(
     ac_var_name == "a" ~ "Access to sanitation",
     ac_var_name == "b" ~ "GDP",
     ac_var_name == "c" ~ "Prop trade of GDP",
     ac_var_name == "d" ~ "Life expectancy at birth",
     ac_var_name == "e" ~ "Supermarkets per 100,000",
     ac_var_name == "f" ~ "Prop population in labor force",
     ac_var_name == "h" ~ "Human capital index",
     ac_var_name == "i" ~ "Government effectivenes",
     ac_var_name == "j" ~ "Food safety capacity",
     ac_var_name == "k" ~ "Rule of law"
   ))

# Create a heatmap of the variable coverage
variable_coverage %>%
  ggplot(aes(y = ac_var_name, x = consumer_iso3c, fill = factor(present_absent))) +
  geom_tile() +
  scale_fill_manual(values = c("white", "#FF0000")) +
  guides(fill = "none") +
  theme_cowplot() +
  theme(axis.text.x = element_blank()) +
  labs(x = "Consuming country", y = "Adaptive capacity variable")

# Get whether an artis country was missing across # of datasets
missing_artis_ac_countries <- data.frame(consumer_iso3c = c(a,b,c,d,e,f,h,i,j,k)) %>%
  count(consumer_iso3c) %>%
  rename(artis = "n") %>%
  filter(consumer_iso3c != "NEI")

# Show which artis countries are covered by artis / which are not
ac_coverage <- bind_rows(consuming_countries %>%
                           mutate(artis = 0) %>%
                           filter(!consumer_iso3c %in% missing_artis_ac_countries), 
                         missing_artis_ac_countries)

ac_coverage %>%
  mutate(artis = as.numeric(artis)) %>%
  filter(artis != 0) %>%
  ggplot(aes(x = artis)) +
  geom_histogram(boundary = 0, binwidth = 1, color = "black") +
  theme_cowplot(15) +
  labs(x = "# AC datasets ARTIS\nconsuming country\nis missing from",
       y = "# countries")

# Calculate number of datasets countries are missing from
variable_coverage %>%
  group_by(consumer_iso3c) %>%
  summarize(num_datasets_missing_from = sum(present_absent)) %>%
  arrange(-num_datasets_missing_from) %>%
  filter(!str_detect(consumer_iso3c, "NEI")) %>%
  write.csv("../data/adaptive capacity/ac_coverage.csv")

variable_coverage %>%
  group_by(ac_var_name) %>%
  summarize(num_countries_missing = sum(present_absent)) %>%
  arrange(-num_countries_missing)
```

```{r Join e / s / ac to prep for risk calculaton}
# Prepare AC data so that it can be joined

# Assets
gdp_clean <- gdp_clean %>%
  rename(gdp = "2019", consumer_iso3c = "Country Code")

trade_gdp_clean <- trade_gdp_clean %>%
  rename(gdp_trade = "2019", consumer_iso3c = "Country Code")
  
sanitation_clean <- sanitation_clean %>%
  rename(sanitation = "Value", consumer_iso3c = "Geography_Code") %>%
  select(sanitation, consumer_iso3c)


# Flexibility
supermarkets_clean <- supermarkets_clean %>%
  rename(supermarkets = "2019", consumer_iso3c = "iso3c")

life_expectancy_clean <- life_expectancy_clean %>%
  rename(life_expectancy = "2019", consumer_iso3c = "Country Code")

prop_population_clean <- prop_population_clean %>%
  rename(consumer_iso3c = "Country Code") %>%
  select(consumer_iso3c, prop_labor)

# Learning

# No longer using mean years schooling
# mean_years_schooling_clean <- mean_years_schooling_clean %>%
#   rename(avg_yrs_educ = "avg_years_education_15_to_64", consumer_iso3c = "Code") %>%
# select(consumer_iso3c, avg_yrs_educ)

hci_clean <- hci_clean %>%
  rename(hci = "2018", consumer_iso3c = "Country Code")


# Social organization
government_effectiveness_clean <- government_effectiveness_clean %>%
  rename(gov_effectiveness = "2019", consumer_iso3c = "Economy ISO3")

fsc_clean <- fsc_clean %>%
  rename(fsc = "Value", consumer_iso3c = "ISO3") %>%
  select(consumer_iso3c, fsc)
  

rol_clean <- rol_clean %>%
  rename(rol = "2019", consumer_iso3c = "Economy ISO3") %>%
  select(consumer_iso3c, rol)

# A LOT OF JOINS
e_s_ac_data <- left_join(gdp_clean, trade_gdp_clean) %>%
  left_join(sanitation_clean) %>%
  left_join(supermarkets_clean) %>%
  left_join(life_expectancy_clean) %>%
  left_join(prop_population_clean) %>%
  left_join(hci_clean) %>%
  left_join(government_effectiveness_clean) %>%
  left_join(fsc_clean) %>%
  left_join(rol_clean) %>%
  right_join(aa_reliance) %>% # Right join to only include consuming ARTIS countries (Aquatic animal reliance Sensitivity)
  left_join(consumer_foreign_dependencies %>% # Add in foreign dependency sensitivity
              filter(year == 2019) %>%
              ungroup() %>%
              select(consumer_iso3c, foreign_dependency)) %>%
  left_join(consumer_stock_change) # Add in exposure data

# Save joined data to output folder
write_parquet(e_s_ac_data, "../output/e_s_ac_data.parquet")
# write_parquet(e_s_ac_data, "../output/e_s_ac_data_entire_portfolio.parquet")

# Remove previous objects to keep data usage small
rm(a, b, c, d, e, f, h, i, j, k, aa_reliance, ac_coverage,
   consumer_foreign_dependencies, consumer_stock_change, consuming_countries, consumption_future, fsc, fsc_clean,
   gdp, gdp_clean, government_effectiveness, government_effectiveness_clean, hci, hci_clean, life_expectancy, life_expectancy_clean, missing_artis_ac_countries, prop_population_clean, rol, rol_clean, sanitation, sanitation_clean, supermarkets, supermarkets_clean, total_labor_force, total_population, total_population_clean, trade_gdp, trade_gdp_clean, variable_coverage)
gc() # Garbage collection to clean up storage
```